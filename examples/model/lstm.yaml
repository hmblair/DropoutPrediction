# lstm.yaml

model:
  class_path: lib.training.modules.PipelineModule
  init_args:
    model:
      class_path: lib.models.recurrent.RecurrentEncoderDecoderWithAttention
      init_args:
        num_embeddings: [4]
        embedding_dims: [64]
        out_size: 2
        num_encoder_layers: 8
        num_decoder_layers: 8
        dropout: 0.4
        num_heads: 8
        attention_dropout: 0.0
        pooling:
          type: mean
          dim: -2
          nonlinearity: exp
    objectives:
      loss:
        class_path: lib.training.optimisation.losses.LogMSELoss
      absolute_error:
        class_path: torch.nn.L1Loss
    name: lstm

data:
  batch_size: 64
  input_variables:
    - [[sequence_embeddings], x]