# ribonanzanet.yaml

model:
  class_path: lib.training.modules.FinetuningModuleDenseHead
  init_args:
    model:
      class_path: models.ribonanzanet.RibonanzaNet
    out_size: 2
    pooling:
      type: 'mean'
      dim: -2
      nonlinearity: exp
    objectives:
      loss:
        class_path: lib.training.optimisation.losses.LogMSELoss
      absolute_error:
        class_path: torch.nn.L1Loss
    name: ribonanzanet

trainer:
  max_epochs: 100
  callbacks:
    - class_path: lib.training.finetuning.unfreeze_scheduler.FineTuningScheduler
      init_args:
        layers_to_unfreeze: [5]
        unfreeze_rate: 5

data:
  batch_size: 32
  input_variables:
    - [[sequence_embeddings], x]



